{"cells":[{"cell_type":"code","execution_count":177,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-02-19T22:27:05.066274Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import re\n","import torch \n","import torch.nn as nn\n","import math\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["Some Helper Functions"]},{"cell_type":"code","execution_count":178,"metadata":{"trusted":true},"outputs":[],"source":["def printUniqueCounts(df, columnName: str = None):\n","    column = None\n","    if columnName is None:\n","        column = df\n","    else:\n","        column = df[columnName]\n","    titles = column.unique()\n","    counts = []\n","    for title in titles:\n","        if pd.isna(title):\n","            count = sum(column.isnull())\n","        else:\n","            count = sum(column==title)\n","        counts.append([title,count])\n","    \n","    counts.sort(key=lambda x: -x[1])\n","    \n","    for item in counts:\n","        print(str(item[0])+\": \"+str(item[1]))\n","\n","def torchEnumerator(tensor):\n","    array = tensor.detach().numpy()\n","    print(\"shape\" + str(array.shape))\n","    return np.nditer(array)"]},{"cell_type":"code","execution_count":179,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(891, 12)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["trainData = pd.read_csv('train.csv')\n","print(trainData.shape)\n","trainData.head()\n"]},{"cell_type":"markdown","metadata":{},"source":["Now it's time to clean up the data for use with our ML algorithm and do some feature engineering.\n","\n","First lets see which columns have NaN / null values:"]},{"cell_type":"code","execution_count":180,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Age has 177 missing data points\n","Cabin has 687 missing data points\n","Embarked has 2 missing data points\n"]}],"source":["for column in trainData.columns:\n","    empty = len(trainData[trainData[column].isnull()])\n","    if empty>0: print(column + \" has \" + str(empty) + \" missing data points\")"]},{"cell_type":"markdown","metadata":{},"source":["We will fill in missing age values with average age for now. In the future we may want to infer the age from the other columns, but for now this will have to suffice."]},{"cell_type":"code","execution_count":181,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average age: \n"]},{"data":{"text/plain":["0      22.000000\n","1      38.000000\n","2      26.000000\n","3      35.000000\n","4      35.000000\n","         ...    \n","886    27.000000\n","887    19.000000\n","888    29.699118\n","889    26.000000\n","890    32.000000\n","Name: Age, Length: 891, dtype: float64"]},"execution_count":181,"metadata":{},"output_type":"execute_result"}],"source":["#fill in missing age values with average age\n","avgAge = trainData[\"Age\"].mean()\n","print(\"Average age: \")\n","trainData[\"Age\"].fillna(avgAge)"]},{"cell_type":"markdown","metadata":{},"source":["To gain a better idea of how to handle the missing values in embarked, lets first see how many people embarked from each port:"]},{"cell_type":"code","execution_count":182,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["S: 644\n","C: 168\n","Q: 77\n","nan: 2\n"]}],"source":["printUniqueCounts(trainData,\"Embarked\")"]},{"cell_type":"markdown","metadata":{},"source":["There are only 3 ports of embarcation, which makes this feature a good candidate for one-hot encoding. Missing values will simply be recorded as 'False' in all embarcation ports"]},{"cell_type":"code","execution_count":183,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin  Embarked_C  Embarked_Q  Embarked_S  \n","0      0         A/5 21171   7.2500   NaN       False       False        True  \n","1      0          PC 17599  71.2833   C85        True       False       False  \n","2      0  STON/O2. 3101282   7.9250   NaN       False       False        True  \n","3      0            113803  53.1000  C123       False       False        True  \n","4      0            373450   8.0500   NaN       False       False        True  "]},"execution_count":183,"metadata":{},"output_type":"execute_result"}],"source":["trainData = pd.get_dummies(trainData,columns=[\"Embarked\"])\n","trainData.head()"]},{"cell_type":"markdown","metadata":{},"source":["The remaining column with missing data is Cabin. This is really two features: cabin area (the letter) and cabin number (the integer). For the sake of simplicity, lets assume the cabin number is not useful, but that the cabin area is. This is a reasonable assumption because the cabin area is likely to have a large effect on the location of the passenger, whereas the cabin number is less likely to have a large effect."]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":184,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cabin Letters\n","None: 687\n","C: 59\n","B: 47\n","D: 33\n","E: 32\n","A: 15\n","F: 13\n","G: 4\n","T: 1\n"]}],"source":["\n","def getCabinLetter(cabin: str):\n","    if cabin is None or not isinstance(cabin,str): return None\n","    result =  re.search(\"^[a-zA-Z]*\",cabin)\n","    if not result: return None\n","    return result[0]\n","    \n","cabinLetter = trainData[\"Cabin\"].apply(getCabinLetter)\n","\n","print(\"Cabin Letters\")\n","printUniqueCounts(cabinLetter)\n"]},{"cell_type":"markdown","metadata":{},"source":["We can see there are only 8 valid options for cabin letter. Being a small number this is a good candidate for one-hot encoding, again solving the missing data issue."]},{"cell_type":"code","execution_count":185,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>...</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Cabin_A</th>\n","      <th>Cabin_B</th>\n","      <th>Cabin_C</th>\n","      <th>Cabin_D</th>\n","      <th>Cabin_E</th>\n","      <th>Cabin_F</th>\n","      <th>Cabin_G</th>\n","      <th>Cabin_T</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare  ...  Embarked_Q  Embarked_S  Cabin_A  \\\n","0      0         A/5 21171   7.2500  ...       False        True    False   \n","1      0          PC 17599  71.2833  ...       False       False    False   \n","2      0  STON/O2. 3101282   7.9250  ...       False        True    False   \n","3      0            113803  53.1000  ...       False        True    False   \n","4      0            373450   8.0500  ...       False        True    False   \n","\n","   Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  \n","0    False    False    False    False    False    False    False  \n","1    False     True    False    False    False    False    False  \n","2    False    False    False    False    False    False    False  \n","3    False     True    False    False    False    False    False  \n","4    False    False    False    False    False    False    False  \n","\n","[5 rows x 21 columns]"]},"execution_count":185,"metadata":{},"output_type":"execute_result"}],"source":["trainData[\"Cabin\"] = cabinLetter\n","trainData = pd.get_dummies(trainData,columns=[\"Cabin\"])\n","trainData.head()"]},{"cell_type":"markdown","metadata":{},"source":["That covers all the missing data, so now we just need to deal with non-numeric data. Lets start by converting Male/Female and True/False to 0/1"]},{"cell_type":"code","execution_count":186,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["None: 687\n","C: 59\n","B: 47\n","D: 33\n","E: 32\n","A: 15\n","F: 13\n","G: 4\n","T: 1\n"]}],"source":["trainData[\"Sex\"] = trainData[\"Sex\"]==\"male\"\n","trainData = trainData*1\n","trainData.head()\n","printUniqueCounts(cabinLetter)"]},{"cell_type":"markdown","metadata":{},"source":["Name and Ticket remain as non-numeric data. We probably could do some NLP to make useful inferences out of the names, but that would be a lot of work and likely not yield a big difference in results. Ticket is also likely not to be very useful info. So lets just delete both columns."]},{"cell_type":"code","execution_count":187,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Cabin_A</th>\n","      <th>Cabin_B</th>\n","      <th>Cabin_C</th>\n","      <th>Cabin_D</th>\n","      <th>Cabin_E</th>\n","      <th>Cabin_F</th>\n","      <th>Cabin_G</th>\n","      <th>Cabin_T</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n","0         0       3    1  22.0      1      0   7.2500           0           0   \n","1         1       1    0  38.0      1      0  71.2833           1           0   \n","2         1       3    0  26.0      0      0   7.9250           0           0   \n","3         1       1    0  35.0      1      0  53.1000           0           0   \n","4         0       3    1  35.0      0      0   8.0500           0           0   \n","\n","   Embarked_S  Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n","0           1        0        0        0        0        0        0        0   \n","1           0        0        0        1        0        0        0        0   \n","2           1        0        0        0        0        0        0        0   \n","3           1        0        0        1        0        0        0        0   \n","4           1        0        0        0        0        0        0        0   \n","\n","   Cabin_T  \n","0        0  \n","1        0  \n","2        0  \n","3        0  \n","4        0  "]},"execution_count":187,"metadata":{},"output_type":"execute_result"}],"source":["trainData = trainData.drop(columns=[\"Name\",\"Ticket\",\"PassengerId\"])\n","trainData.head()"]},{"cell_type":"markdown","metadata":{},"source":["Finally lets do a little bit of feature engineering. Most of these features look pretty useful as is, but Sibsp and Parch stand out as being a potentially useful target for a little bit of engineering. \n","SibSp: siblings and spouses\n","Parch: parents and children\n","\n","We can combine these two to get family size. Total family size might be an important metric so lets make an additional column for family size "]},{"cell_type":"code","execution_count":188,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Cabin_A</th>\n","      <th>Cabin_B</th>\n","      <th>Cabin_C</th>\n","      <th>Cabin_D</th>\n","      <th>Cabin_E</th>\n","      <th>Cabin_F</th>\n","      <th>Cabin_G</th>\n","      <th>Cabin_T</th>\n","      <th>FamSize</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n","0         0       3    1  22.0      1      0   7.2500           0           0   \n","1         1       1    0  38.0      1      0  71.2833           1           0   \n","2         1       3    0  26.0      0      0   7.9250           0           0   \n","3         1       1    0  35.0      1      0  53.1000           0           0   \n","4         0       3    1  35.0      0      0   8.0500           0           0   \n","\n","   Embarked_S  Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n","0           1        0        0        0        0        0        0        0   \n","1           0        0        0        1        0        0        0        0   \n","2           1        0        0        0        0        0        0        0   \n","3           1        0        0        1        0        0        0        0   \n","4           1        0        0        0        0        0        0        0   \n","\n","   Cabin_T  FamSize  \n","0        0        1  \n","1        0        1  \n","2        0        0  \n","3        0        1  \n","4        0        0  "]},"execution_count":188,"metadata":{},"output_type":"execute_result"}],"source":["\n","trainData.insert(len(trainData.columns),\"FamSize\",trainData[\"SibSp\"]+trainData[\"Parch\"])\n","trainData.head()"]},{"cell_type":"markdown","metadata":{},"source":["Finally we have to normalize the data. Lets use zscore normalization on Age and Fare:\n","**temporarily dropping Age to fix bugs**"]},{"cell_type":"code","execution_count":189,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Cabin_A</th>\n","      <th>Cabin_B</th>\n","      <th>Cabin_C</th>\n","      <th>Cabin_D</th>\n","      <th>Cabin_E</th>\n","      <th>Cabin_F</th>\n","      <th>Cabin_G</th>\n","      <th>Cabin_T</th>\n","      <th>FamSize</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-0.502445</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.786845</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.488854</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.420730</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.486337</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Pclass  Sex  SibSp  Parch      Fare  Embarked_C  Embarked_Q  Embarked_S  \\\n","0       3    1      1      0 -0.502445           0           0           1   \n","1       1    0      1      0  0.786845           1           0           0   \n","2       3    0      0      0 -0.488854           0           0           1   \n","3       1    0      1      0  0.420730           0           0           1   \n","4       3    1      0      0 -0.486337           0           0           1   \n","\n","   Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  \\\n","0        0        0        0        0        0        0        0        0   \n","1        0        0        1        0        0        0        0        0   \n","2        0        0        0        0        0        0        0        0   \n","3        0        0        1        0        0        0        0        0   \n","4        0        0        0        0        0        0        0        0   \n","\n","   FamSize  \n","0        1  \n","1        1  \n","2        0  \n","3        1  \n","4        0  "]},"execution_count":189,"metadata":{},"output_type":"execute_result"}],"source":["from scipy.stats import zscore\n","colsToNormalize = [\"Age\",\"Fare\"]\n","trainData[colsToNormalize] = trainData[colsToNormalize].apply(zscore)\n","\n","#drop age for now\n","\n","trainDataY = trainData[\"Survived\"]\n","trainDataX = trainData.drop(columns=[\"Survived\",\"Age\"])\n","trainDataX.head()\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Now we have prepared the data for our ML algorithm.\n","\n","Lets create a model with 3 hidden layers, of 20, 8 and 5 neurons. Each hidden layer will have a ReLU activation function. The final output neuron will have a sigmoid activation function.\n","For the loss function we will use binary cross entropy."]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":195,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([891, 17])\n"]},{"ename":"RuntimeError","evalue":"size mismatch, got input (891), mat (891x17), vec (2)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[195], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m---> 55\u001b[0m     yHat \u001b[38;5;241m=\u001b[39m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     l \u001b[38;5;241m=\u001b[39m loss(Y,yHat)\n\u001b[0;32m     57\u001b[0m     l\u001b[38;5;241m.\u001b[39mbackward()\n","Cell \u001b[1;32mIn[195], line 42\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     40\u001b[0m layer \u001b[38;5;241m=\u001b[39m layers[i]\n\u001b[0;32m     41\u001b[0m function \u001b[38;5;241m=\u001b[39m layer[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 42\u001b[0m prod \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlayerWeights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m z \u001b[38;5;241m=\u001b[39m prod \u001b[38;5;241m+\u001b[39m layerBiases[i]\n\u001b[0;32m     44\u001b[0m A \u001b[38;5;241m=\u001b[39m function(z)\n","\u001b[1;31mRuntimeError\u001b[0m: size mismatch, got input (891), mat (891x17), vec (2)"]}],"source":["inCount = trainDataX.shape[1]#number of inputs\n","layerWeights = []\n","layerBiases = []\n","\n","relu = nn.ReLU()\n","sigmoid = nn.Sigmoid()\n","layers = [[20,relu],[8,relu],[5,relu],[1,sigmoid]]#[node count, activation function]\n","layerCount = len(layers)\n","loss = nn.BCELoss()\n","learningRate = 0.01\n","initialParameterMin = -.1\n","initialParameterMax = .1\n","\n","lastNodeCount = inCount\n","for layer in layers:\n","    nodeCount = layer[0]\n","    weights = torch.FloatTensor((lastNodeCount,nodeCount))\n","    biases = torch.FloatTensor(nodeCount)\n","\n","    for arr in [weights,biases]:\n","        arr.uniform_(initialParameterMin,initialParameterMax)\n","        arr.requires_grad_(True)\n","\n","\n","    layerWeights.append(weights)\n","    layerBiases.append(biases)\n","    lastNodeCount = nodeCount\n","\n","def printNan(V):\n","    nanCount = 0\n","    for item in torchEnumerator(V):\n","        if math.isnan(item): nanCount+=1\n","    ratio = nanCount/len(V)\n","    print(str(ratio*100)+\"% Nan\")\n","\n","def forward(X):\n","    A = X\n","    print(X.shape)\n","    for i in range(layerCount):\n","        layer = layers[i]\n","        function = layer[1]\n","        prod = torch.matmul(A,layerWeights[i])\n","        z = prod + layerBiases[i]\n","        A = function(z)\n","    A = A.squeeze()\n","    return A\n","        \n","        \n","X = torch.tensor(trainDataX.values,dtype=torch.float32)\n","Y = torch.tensor(trainDataY.values,dtype=torch.float32)\n","\n","losses = []\n","iterations = 100\n","for epoch in range(iterations):\n","    yHat = forward(X)\n","    l = loss(Y,yHat)\n","    l.backward()\n","    print(l)\n","    print(sum(weights.grad))\n","    with torch.no_grad():\n","        for i in range(layerCount):\n","            weights = layerWeights[i]\n","            biases = layerBiases[i]\n","            weights-=weights.grad*learningRate\n","            biases-=biases.grad*learningRate\n","            weights.grad.zero_()\n","            biases.grad.zero_()\n","\n","    \n","    losses.append(l)\n","\n","\n","print(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"nbformat":4,"nbformat_minor":4}
