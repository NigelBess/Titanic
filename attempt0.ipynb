{"cells":[{"cell_type":"code","execution_count":740,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-02-19T22:27:05.066274Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Dev\\Titanic\\Data\\submission.csv\n","c:\\Dev\\Titanic\\Data\\test.csv\n","c:\\Dev\\Titanic\\Data\\train.csv\n"]},{"data":{"text/plain":["<torch._C.Generator at 0x268a2c52dd0>"]},"execution_count":740,"metadata":{},"output_type":"execute_result"}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import re\n","import torch.nn as nn\n","import torch\n","import math\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from typing import List\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","#local\n","dataFolder = os.path.join(os.getcwd(),\"Data\")\n","#Kaggle\n","#dataFolder = \"/kaggle/input/titanic\"\n","for dirname, _, filenames in os.walk(dataFolder):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","        \n","RANDOM_SEED = 41\n","torch.manual_seed(RANDOM_SEED)"]},{"cell_type":"markdown","metadata":{},"source":["Some Helper Functions"]},{"cell_type":"code","execution_count":741,"metadata":{"trusted":true},"outputs":[],"source":["def printUniqueCounts(df, columnName: str = None):\n","    column = None\n","    if columnName is None:\n","        column = df\n","    else:\n","        column = df[columnName]\n","    titles = column.unique()\n","    counts = []\n","    for title in titles:\n","        if pd.isna(title):\n","            count = sum(column.isnull())\n","        else:\n","            count = sum(column==title)\n","        counts.append([title,count])\n","    \n","    counts.sort(key=lambda x: -x[1])\n","    \n","    for item in counts:\n","        print(str(item[0])+\": \"+str(item[1]))\n","\n","def torchEnumerator(tensor):\n","    array = tensor.detach().numpy()\n","    print(\"shape\" + str(array.shape))\n","    return np.nditer(array)"]},{"cell_type":"code","execution_count":742,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(891, 12)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":742,"metadata":{},"output_type":"execute_result"}],"source":["trainFilePath = os.path.join(dataFolder,'train.csv')\n","trainData = pd.read_csv(trainFilePath)\n","print(trainData.shape)\n","trainDataRows = trainData.shape[0]\n","trainData.head()\n"]},{"cell_type":"markdown","metadata":{},"source":["We will concat the test data to the training Data, so that all data manipulation happens to both data sets"]},{"cell_type":"code","execution_count":743,"metadata":{},"outputs":[],"source":["testFilePath = os.path.join(dataFolder,'test.csv')\n","testData = pd.read_csv(testFilePath)\n","testDataRows = testData.shape[0]\n","trainData = pd.concat([trainData,testData])"]},{"cell_type":"markdown","metadata":{},"source":["Now it's time to clean up the data for use with our ML algorithm and do some feature engineering.\n","\n","First lets see which columns have NaN / null values:"]},{"cell_type":"code","execution_count":744,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Survived has 418 missing data points\n","Age has 263 missing data points\n","Fare has 1 missing data points\n","Cabin has 1014 missing data points\n","Embarked has 2 missing data points\n"]}],"source":["for column in trainData.columns:\n","    empty = len(trainData[trainData[column].isnull()])\n","    if empty>0: print(column + \" has \" + str(empty) + \" missing data points\")"]},{"cell_type":"markdown","metadata":{},"source":["We will fill in missing age values with average age for now. In the future we may want to infer the age from the other columns, but for now this will have to suffice."]},{"cell_type":"code","execution_count":745,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average age: 29.881137667304014\n"]}],"source":["#fill in missing age values with average age\n","avgAge = trainData[\"Age\"].mean()\n","print(F\"Average age: {avgAge}\")\n","trainData[\"Age\"].fillna(avgAge, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["To gain a better idea of how to handle the missing values in embarked, lets first see how many people embarked from each port:"]},{"cell_type":"code","execution_count":746,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["S: 914\n","C: 270\n","Q: 123\n","nan: 2\n"]}],"source":["\n","printUniqueCounts(trainData,\"Embarked\")"]},{"cell_type":"markdown","metadata":{},"source":["For the two passengers with unknown ports of embarcation, lets simply fill in the data with the most likely possibility: S"]},{"cell_type":"code","execution_count":747,"metadata":{},"outputs":[],"source":["trainData[\"Embarked\"].fillna(\"S\", inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["There are only 3 ports of embarcation, which makes this feature a good candidate for one-hot encoding. Missing values will simply be recorded as 'False' in all embarcation ports"]},{"cell_type":"code","execution_count":748,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1       0.0       3   \n","1            2       1.0       1   \n","2            3       1.0       3   \n","3            4       1.0       1   \n","4            5       0.0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin  Embarked_C  Embarked_Q  Embarked_S  \n","0      0         A/5 21171   7.2500   NaN       False       False        True  \n","1      0          PC 17599  71.2833   C85        True       False       False  \n","2      0  STON/O2. 3101282   7.9250   NaN       False       False        True  \n","3      0            113803  53.1000  C123       False       False        True  \n","4      0            373450   8.0500   NaN       False       False        True  "]},"execution_count":748,"metadata":{},"output_type":"execute_result"}],"source":["trainData = pd.get_dummies(trainData,columns=[\"Embarked\"])\n","trainData.head()"]},{"cell_type":"markdown","metadata":{},"source":["The remaining column with missing data is Cabin. This is really two features: cabin area (the letter) and cabin number (the integer). For the sake of simplicity, lets assume the cabin number is not useful, but that the cabin area is. This is a reasonable assumption because the cabin area is likely to have a large effect on the location of the passenger, whereas the cabin number is less likely to have a large effect."]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":749,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cabin Letters\n","None: 1014\n","C: 94\n","B: 65\n","D: 46\n","E: 41\n","A: 22\n","F: 21\n","G: 5\n","T: 1\n"]}],"source":["\n","def getCabinLetter(cabin: str):\n","    if cabin is None or not isinstance(cabin,str): return None\n","    result =  re.search(\"^[a-zA-Z]*\",cabin)\n","    if not result: return None\n","    return result[0]\n","    \n","cabinLetter = trainData[\"Cabin\"].apply(getCabinLetter)\n","\n","print(\"Cabin Letters\")\n","printUniqueCounts(cabinLetter)\n"]},{"cell_type":"markdown","metadata":{},"source":["We can see there are only 8 valid options for cabin letter. Being a small number this is a good candidate for one-hot encoding, again solving the missing data issue."]},{"cell_type":"code","execution_count":750,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>...</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Cabin_A</th>\n","      <th>Cabin_B</th>\n","      <th>Cabin_C</th>\n","      <th>Cabin_D</th>\n","      <th>Cabin_E</th>\n","      <th>Cabin_F</th>\n","      <th>Cabin_G</th>\n","      <th>Cabin_T</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1       0.0       3   \n","1            2       1.0       1   \n","2            3       1.0       3   \n","3            4       1.0       1   \n","4            5       0.0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare  ...  Embarked_Q  Embarked_S  Cabin_A  \\\n","0      0         A/5 21171   7.2500  ...       False        True    False   \n","1      0          PC 17599  71.2833  ...       False       False    False   \n","2      0  STON/O2. 3101282   7.9250  ...       False        True    False   \n","3      0            113803  53.1000  ...       False        True    False   \n","4      0            373450   8.0500  ...       False        True    False   \n","\n","   Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  \n","0    False    False    False    False    False    False    False  \n","1    False     True    False    False    False    False    False  \n","2    False    False    False    False    False    False    False  \n","3    False     True    False    False    False    False    False  \n","4    False    False    False    False    False    False    False  \n","\n","[5 rows x 21 columns]"]},"execution_count":750,"metadata":{},"output_type":"execute_result"}],"source":["trainData[\"Cabin\"] = cabinLetter\n","trainData = pd.get_dummies(trainData,columns=[\"Cabin\"])\n","trainData.head()"]},{"cell_type":"markdown","metadata":{},"source":["That covers all the missing data, so now we just need to deal with non-numeric data. Lets start by converting Male/Female and True/False to 0/1"]},{"cell_type":"code","execution_count":751,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>...</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Cabin_A</th>\n","      <th>Cabin_B</th>\n","      <th>Cabin_C</th>\n","      <th>Cabin_D</th>\n","      <th>Cabin_E</th>\n","      <th>Cabin_F</th>\n","      <th>Cabin_G</th>\n","      <th>Cabin_T</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1       0.0       3   \n","1            2       1.0       1   \n","2            3       1.0       3   \n","3            4       1.0       1   \n","4            5       0.0       3   \n","\n","                                                Name  Sex   Age  SibSp  Parch  \\\n","0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n","2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n","4                           Allen, Mr. William Henry    1  35.0      0      0   \n","\n","             Ticket     Fare  ...  Embarked_Q  Embarked_S  Cabin_A  Cabin_B  \\\n","0         A/5 21171   7.2500  ...           0           1        0        0   \n","1          PC 17599  71.2833  ...           0           0        0        0   \n","2  STON/O2. 3101282   7.9250  ...           0           1        0        0   \n","3            113803  53.1000  ...           0           1        0        0   \n","4            373450   8.0500  ...           0           1        0        0   \n","\n","   Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  \n","0        0        0        0        0        0        0  \n","1        1        0        0        0        0        0  \n","2        0        0        0        0        0        0  \n","3        1        0        0        0        0        0  \n","4        0        0        0        0        0        0  \n","\n","[5 rows x 21 columns]"]},"execution_count":751,"metadata":{},"output_type":"execute_result"}],"source":["trainData[\"Sex\"] = trainData[\"Sex\"]==\"male\"\n","trainData = trainData*1\n","trainData.head()"]},{"cell_type":"markdown","metadata":{},"source":["Name and Ticket remain as non-numeric data. We probably could do some NLP to make useful inferences out of the names, but that would be a lot of work and likely not yield a big difference in results. Ticket is also likely not to be very useful info. So lets just delete both columns."]},{"cell_type":"code","execution_count":752,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Cabin_A</th>\n","      <th>Cabin_B</th>\n","      <th>Cabin_C</th>\n","      <th>Cabin_D</th>\n","      <th>Cabin_E</th>\n","      <th>Cabin_F</th>\n","      <th>Cabin_G</th>\n","      <th>Cabin_T</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n","0       0.0       3    1  22.0      1      0   7.2500           0           0   \n","1       1.0       1    0  38.0      1      0  71.2833           1           0   \n","2       1.0       3    0  26.0      0      0   7.9250           0           0   \n","3       1.0       1    0  35.0      1      0  53.1000           0           0   \n","4       0.0       3    1  35.0      0      0   8.0500           0           0   \n","\n","   Embarked_S  Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n","0           1        0        0        0        0        0        0        0   \n","1           0        0        0        1        0        0        0        0   \n","2           1        0        0        0        0        0        0        0   \n","3           1        0        0        1        0        0        0        0   \n","4           1        0        0        0        0        0        0        0   \n","\n","   Cabin_T  \n","0        0  \n","1        0  \n","2        0  \n","3        0  \n","4        0  "]},"execution_count":752,"metadata":{},"output_type":"execute_result"}],"source":["trainData = trainData.drop(columns=[\"Name\",\"Ticket\",\"PassengerId\"])\n","trainData.head()"]},{"cell_type":"code","execution_count":753,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0: 549\n","nan: 418\n","1.0: 342\n"]}],"source":["printUniqueCounts(trainData,\"Survived\")"]},{"cell_type":"markdown","metadata":{},"source":["Now lets do a little bit of feature engineering. Most of these features look pretty useful as is, but Sibsp and Parch stand out as being a potentially useful target for a little bit of engineering. \n","SibSp: siblings and spouses\n","Parch: parents and children\n","\n","We can combine these two to get family size. Total family size might be an important metric so lets make an additional column for family size "]},{"cell_type":"code","execution_count":754,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Cabin_A</th>\n","      <th>Cabin_B</th>\n","      <th>Cabin_C</th>\n","      <th>Cabin_D</th>\n","      <th>Cabin_E</th>\n","      <th>Cabin_F</th>\n","      <th>Cabin_G</th>\n","      <th>Cabin_T</th>\n","      <th>FamSize</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n","0       0.0       3    1  22.0      1      0   7.2500           0           0   \n","1       1.0       1    0  38.0      1      0  71.2833           1           0   \n","2       1.0       3    0  26.0      0      0   7.9250           0           0   \n","3       1.0       1    0  35.0      1      0  53.1000           0           0   \n","4       0.0       3    1  35.0      0      0   8.0500           0           0   \n","\n","   Embarked_S  Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n","0           1        0        0        0        0        0        0        0   \n","1           0        0        0        1        0        0        0        0   \n","2           1        0        0        0        0        0        0        0   \n","3           1        0        0        1        0        0        0        0   \n","4           1        0        0        0        0        0        0        0   \n","\n","   Cabin_T  FamSize  \n","0        0        1  \n","1        0        1  \n","2        0        0  \n","3        0        1  \n","4        0        0  "]},"execution_count":754,"metadata":{},"output_type":"execute_result"}],"source":["\n","trainData.insert(len(trainData.columns),\"FamSize\",trainData[\"SibSp\"]+trainData[\"Parch\"])\n","trainData.head()"]},{"cell_type":"markdown","metadata":{},"source":["To complete our feature engineering we will to normalize the data. Lets use zscore normalization on Age and Fare:"]},{"cell_type":"code","execution_count":755,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Cabin_A</th>\n","      <th>Cabin_B</th>\n","      <th>Cabin_C</th>\n","      <th>Cabin_D</th>\n","      <th>Cabin_E</th>\n","      <th>Cabin_F</th>\n","      <th>Cabin_G</th>\n","      <th>Cabin_T</th>\n","      <th>FamSize</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>-0.611972</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-0.503402</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.630431</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.734222</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>-0.301371</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.490356</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.397481</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.382778</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.397481</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.487940</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked_C  \\\n","0       0.0       3    1 -0.611972      1      0 -0.503402           0   \n","1       1.0       1    0  0.630431      1      0  0.734222           1   \n","2       1.0       3    0 -0.301371      0      0 -0.490356           0   \n","3       1.0       1    0  0.397481      1      0  0.382778           0   \n","4       0.0       3    1  0.397481      0      0 -0.487940           0   \n","\n","   Embarked_Q  Embarked_S  Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  \\\n","0           0           1        0        0        0        0        0   \n","1           0           0        0        0        1        0        0   \n","2           0           1        0        0        0        0        0   \n","3           0           1        0        0        1        0        0   \n","4           0           1        0        0        0        0        0   \n","\n","   Cabin_F  Cabin_G  Cabin_T  FamSize  \n","0        0        0        0        1  \n","1        0        0        0        1  \n","2        0        0        0        0  \n","3        0        0        0        1  \n","4        0        0        0        0  "]},"execution_count":755,"metadata":{},"output_type":"execute_result"}],"source":["colsToNormalize = [\"Age\",\"Fare\"]\n","scalers = {}\n","for col in colsToNormalize:\n","    scaler = StandardScaler()\n","    scalers[col] = scaler\n","    colData = trainData[col].values.reshape(-1,1)\n","    scaler.fit(colData)\n","    trainData[col] = scaler.transform(colData)\n","trainData.head()\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Recall how we appended the test data to the training data in order to manipulate both sets simultaneously. Lets now undo that."]},{"cell_type":"code","execution_count":756,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Cabin_A</th>\n","      <th>Cabin_B</th>\n","      <th>Cabin_C</th>\n","      <th>Cabin_D</th>\n","      <th>Cabin_E</th>\n","      <th>Cabin_F</th>\n","      <th>Cabin_G</th>\n","      <th>Cabin_T</th>\n","      <th>FamSize</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.358655</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.492208</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1.329283</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-0.508234</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2.494035</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.456291</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>-0.223721</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.476102</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>-0.611972</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>-0.406039</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked_C  \\\n","0       NaN       3    1  0.358655      0      0 -0.492208           0   \n","1       NaN       3    0  1.329283      1      0 -0.508234           0   \n","2       NaN       2    1  2.494035      0      0 -0.456291           0   \n","3       NaN       3    1 -0.223721      0      0 -0.476102           0   \n","4       NaN       3    0 -0.611972      1      1 -0.406039           0   \n","\n","   Embarked_Q  Embarked_S  Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  \\\n","0           1           0        0        0        0        0        0   \n","1           0           1        0        0        0        0        0   \n","2           1           0        0        0        0        0        0   \n","3           0           1        0        0        0        0        0   \n","4           0           1        0        0        0        0        0   \n","\n","   Cabin_F  Cabin_G  Cabin_T  FamSize  \n","0        0        0        0        0  \n","1        0        0        0        1  \n","2        0        0        0        0  \n","3        0        0        0        0  \n","4        0        0        0        2  "]},"execution_count":756,"metadata":{},"output_type":"execute_result"}],"source":["testData = trainData.tail(testDataRows)\n","trainData = trainData.head(trainDataRows)\n","testData.head()"]},{"cell_type":"markdown","metadata":{},"source":["And in order to train the model without overfitting, lets create a training data set and a test data set upon which to verify generalization. We will use a random subset of 20% of rows as test data and the last 80% of rows as training data. Lets write a class to handle our data storage and conversion to tensors"]},{"cell_type":"code","execution_count":757,"metadata":{},"outputs":[],"source":["\n","class DataSet:\n","    X = \"X\",\n","    Y = \"Y\",\n","\n","    def __init__(self, X: pd.DataFrame, Y: pd.DataFrame):\n","        if X.shape[0] != Y.shape[0]:\n","            raise ValueError(\"Row count mismatch between X and Y\")\n","\n","        #initialize self.datasets\n","        self.datasets = {DataSet.X: X, DataSet.Y: Y}       \n","\n","        #convert data to torch tensor format\n","        for setName in self.datasets:\n","            set = self.datasets[setName]\n","            if set is None: continue\n","            tens = torch.tensor(set.values, dtype=torch.float32)\n","            if len(set.shape)==1:\n","                tens.unsqueeze_(1)\n","            self.datasets[setName] = tens\n","\n","        #make sure we can run gradient descent on x training data\n","        self.get(DataSet.X).requires_grad_(True)       \n","    \n","    @property\n","    def InputCount(self): return self.get(DataSet.X).shape[1]\n","\n","    @property\n","    def Rows(self): return self.get(DataSet.X).shape[0]\n","\n","    def assertSetExistence(self,setName):\n","        if setName not in self.datasets:\n","            raise ValueError(f\"Dataset '{setName}' not found\")\n","        \n","    def set(self, setName: str, value: torch.Tensor):\n","        self.assertSetExistence(setName)\n","        self.datasets[setName] = value\n","    \n","    def get(self, setName: str) -> torch.Tensor:\n","        self.assertSetExistence(setName)\n","        return self.datasets[setName]\n","    \n","\n","    def set_to_cuda(self):\n","        with torch.no_grad():\n","            for setName in self.datasets:\n","                set = self.datasets[setName]\n","                if set is None: continue\n","                self.datasets[setName] = set.cuda()\n"]},{"cell_type":"markdown","metadata":{},"source":["Lets split the data between input (X) and output (Y) and divide it between training data and cross-validation data. We will store each dataset in an instance of the newly created dataset class. Let's alsp store the test data as a DataSet"]},{"cell_type":"code","execution_count":758,"metadata":{},"outputs":[],"source":["def SeparateData(dataFrame:pd.DataFrame):\n","    yColName = \"Survived\"\n","    if yColName not in dataFrame.columns:\n","        Y = None\n","    else:\n","        Y= dataFrame[yColName]\n","    X = dataFrame.drop(columns=yColName)\n","    return (X,Y)\n","\n","(X,Y) = SeparateData(trainData)\n","unsplitData = DataSet(X,Y)#save this for later\n","\n","X,XVal,Y,YVal = train_test_split(X,Y,test_size=.2,random_state=RANDOM_SEED)\n","trainData = DataSet(X,Y)\n","valData = DataSet(XVal,YVal)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Now we have prepared the data for our ML algorithm.\n","\n","Lets create a model. To start we will define a generic model which can be tweaked based on user parameters"]},{"cell_type":"code","execution_count":759,"metadata":{},"outputs":[],"source":["class Layer(nn.Module):\n","    def __init__(self, nodeCount: int, activation_function: nn.Module):\n","        super().__init__()\n","        self.nodeCount = nodeCount\n","        self.activation_function = activation_function\n","\n","    def setInputCount(self,inputCount:int):\n","        self.linear = nn.Linear(inputCount,self.nodeCount)\n","    \n","    def forward(self,x): return self.activation_function(self.linear(x))\n","\n","    def set_to_cuda(self):\n","        self.linear = self.linear.cuda()\n","        self.activation_function = self.activation_function.cuda()\n","\n","class Model(nn.Module):\n","    def __init__(self, input_feature_count:int, layers: nn.ModuleList):\n","        super().__init__()\n","        self.input_feature_count = input_feature_count\n","        lastNodeCount = input_feature_count\n","        for layer in layers:\n","            layer.setInputCount(lastNodeCount)\n","            lastNodeCount = layer.nodeCount\n","\n","        self.layers = layers\n","            \n","\n","    def forward(self,x:torch.Tensor):\n","        for l in self.layers: x = l.forward(x)\n","        return x\n","    \n","    def set_to_cuda(self):\n","        for layer in self.layers:\n","            layer.set_to_cuda()\n","\n","def buildLayers(hiddenLayers=[]):\n","    layers = nn.ModuleList()\n","    for i in hiddenLayers: layers.append(Layer(i,nn.ReLU()))\n","    layers.append(Layer(1,nn.Sigmoid()))\n","    return layers\n"]},{"cell_type":"markdown","metadata":{},"source":["Some Helper functions for calculating accuracy, f1 score, etc..\n"]},{"cell_type":"code","execution_count":760,"metadata":{},"outputs":[],"source":["def getPrediction(yHat:np.array): \n","    return (yHat>0.5).astype(int)\n","\n","def accuracy(prediction:np.array,target:np.array): #arrays should be 0 or 1\n","    return (sum(prediction==target)/len(prediction)).item()\n","    \n","def f1Score(prediction:np.array,target:np.array):#arrays should be 0 or 1\n","    actualPositives = sum(target)\n","    predictedPositives = sum(prediction)\n","    truePositives = sum(target*prediction)\n","    if actualPositives == 0: \n","        recall = 0\n","    else:\n","        recall = truePositives/actualPositives\n","\n","    if predictedPositives == 0:\n","        precision = 0\n","    else:\n","        precision = truePositives/predictedPositives\n","    if precision == 0 or recall == 0:\n","        return 0\n","    f1 = 2/(1/precision+ 1/recall)\n","    return f1"]},{"cell_type":"markdown","metadata":{},"source":["And let's define a class for keeping track of training results"]},{"cell_type":"code","execution_count":761,"metadata":{},"outputs":[],"source":["class TrainingResult():\n","    def __init__(self):\n","        self.f1_score = []\n","        self.accuracy = []\n","        self.loss = []\n","\n","class TrainingParams():\n","    def __init__(self):\n","        self.learningRate = 1e-2\n","        self.regularizationConstant = 1e-2\n","        self.iterations = 100"]},{"cell_type":"markdown","metadata":{},"source":["We'll define a function that we can use to train a model based on tweakable parameters:"]},{"cell_type":"code","execution_count":762,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","\n","\n","def trainModel(dataSets:List[DataSet], model:Model, loss_function:nn.modules.loss._Loss, trainingParams:TrainingParams)->List[TrainingResult]: \n","    trainData = dataSets[0]\n","    print(F\"Training Model. Features {trainData.InputCount}, Samples {trainData.Rows}. Iterations: {iterations}\")\n","\n","\n","\n","    results:List[TrainingResult] = []\n","    for _ in dataSets:\n","        results.append(TrainingResult())\n","\n","    optimizer = torch.optim.Adam(params=model.parameters(),lr=trainingParams.learningRate,weight_decay=trainingParams.regularizationConstant)\n","\n","    if torch.cuda.is_available():\n","        for set in dataSets:\n","            set.set_to_cuda()\n","        model.set_to_cuda()\n","        print(F\"Running on {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n","    else:\n","        print(\"Running on CPU\")\n","    \n","    def convertToNumpy(tens):\n","        if torch.cuda.is\n","\n","    for _ in range(trainingParams.iterations):\n","        trainingLoss = None\n","        for (set,result) in  zip(dataSets,results):\n","            x = set.get(DataSet.X)\n","            y = set.get(DataSet.Y)\n","            yHat = model.forward(x)\n","\n","            l = loss_function(yHat,y)\n","            if trainingLoss is None: trainingLoss = l\n","            result.loss.append(l.item())\n","\n","            y = convertToNumpy(y)\n","            yHat = yHat.squeeze(1).cpu().detach().numpy()\n","            prediction = getPrediction(yHat)\n","\n","            acc = accuracy(prediction,y)\n","            result.accuracy.append(acc)\n","\n","            f1 = f1Score(prediction,y)\n","            result.f1_score.append(f1)\n","        \n","\n","        trainingLoss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    print(f\"returning {len(results)} results for {len(dataSets)} data sets\")\n","    return results\n","       \n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Tweak the parameters here:"]},{"cell_type":"code","execution_count":763,"metadata":{},"outputs":[],"source":["hiddenLayers = [100,50,2]\n","layers = buildLayers(hiddenLayers)\n","model = Model(trainData.InputCount,layers)\n","params = TrainingParams() \n","params.learningRate = 1e-2\n","params.regularizationConstant = 1e-2\n","params.iterations = 600\n","loss = nn.BCELoss()\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Let's train the model"]},{"cell_type":"code","execution_count":764,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Model. Features 18, Samples 712. Iterations: 385\n","Running on NVIDIA GeForce GTX 1080\n"]},{"ename":"TypeError","evalue":"can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[764], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataSets \u001b[38;5;241m=\u001b[39m [trainData,valData]\n\u001b[1;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataSets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataSets\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainingParams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[762], line 32\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(dataSets, model, loss_function, trainingParams)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainingLoss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: trainingLoss \u001b[38;5;241m=\u001b[39m l\n\u001b[0;32m     30\u001b[0m result\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mappend(l\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m---> 32\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m yHat \u001b[38;5;241m=\u001b[39m yHat\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     34\u001b[0m prediction \u001b[38;5;241m=\u001b[39m getPrediction(yHat)\n","\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]}],"source":["dataSets = [trainData,valData]\n","results = trainModel(dataSets=dataSets,model=model,loss_function=loss,trainingParams=params)"]},{"cell_type":"markdown","metadata":{},"source":["And Plot the results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = range(0,params.iterations)\n","trainingResult = results[0]\n","validationResult = results[1]\n","\n","fig = plt.figure()\n","ax1 = plt.gca()\n","ax1.plot(epochs,trainingResult.loss,color=\"blue\")\n","ax1.plot(epochs,validationResult.loss, color=\"purple\")\n","ax2 = ax1.twinx()\n","ax2.plot(epochs,trainingResult.accuracy,color=\"green\")\n","ax2.plot(epochs,validationResult.accuracy,color=\"orange\")\n","ax2.plot(epochs,trainingResult.f1_score,color=\"cyan\")\n","ax2.plot(epochs,validationResult.f1_score,color=\"red\")\n","\n","valf1 = validationResult.f1_score\n","maxEpoch = np.argmax(valf1)\n","\n","\n","print(f\"Peak cross validation f1: {valf1[maxEpoch]} at epoch {maxEpoch} with accuracy {validationResult.accuracy[maxEpoch]}. Training Acc {trainingResult.accuracy[maxEpoch]}\")"]},{"cell_type":"markdown","metadata":{},"source":["These numbers seem to give us a decent model that generalizes well. Lets run this same model on ALL the data this time, using the metaparameters we got from using the cross validation set:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["params.iterations = maxEpoch+1\n","print(F\"Now training on full  {unsplitData.Rows} x {unsplitData.InputCount} data set\")\n","layers = buildLayers(hiddenLayers)\n","model = Model(unsplitData.InputCount,layers)\n","results = trainModel(dataSets=[unsplitData],model=model,loss_function=loss,trainingParams=params)\n","trainingResult = results[0]\n","a = 12"]},{"cell_type":"markdown","metadata":{},"source":["And lets do the same analysis on the trained model to verify that it is working"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure()\n","ax1 = plt.gca()\n","epochs = range(0,params.iterations)\n","ax1.plot(epochs,trainingResult.loss,color=\"blue\")\n","ax2 = ax1.twinx()\n","ax2.plot(epochs,trainingResult.accuracy,color=\"green\")\n","ax2.plot(epochs,trainingResult.f1_score,color=\"cyan\")\n","\n","maxEpoch = np.argmax(trainingResult.f1_score)\n","print(f\"Train f1 at at epoch {maxEpoch}: {trainingResult.f1_score[maxEpoch]} with accuracy {trainingResult.accuracy[maxEpoch]}\")"]},{"cell_type":"markdown","metadata":{},"source":["Now that we have a trained model, lets run predictions on the test set. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["(XTest,YTest) = SeparateData(testData)\n","testData = DataSet(XTest,YTest)\n","if torch.cuda.is_available(): testData.set_to_cuda()\n","X = testData.get(DataSet.X)\n","yHat = getPrediction(model.forward(X))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testData = pd.read_csv(testFilePath)\n","testData[\"Survived\"] = yHat.cpu().numpy()\n","testData[\"Survived\"] = testData[\"Survived\"].astype(int)\n","testData.head()\n"]},{"cell_type":"markdown","metadata":{},"source":["Now let's verify that our results make sense"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def barPlotSurvivalByBrackets(data,column,bracketCount,title=\"\"):\n","    x = data[column].values\n","    y = data[\"Survived\"].astype(int).values\n","\n","    minX = min(x)\n","    maxX = max(x)\n","    rangeX = maxX-minX\n","    bracketWidth = rangeX/bracketCount\n","    \n","    brackets = {}\n","    for i in range(bracketCount):\n","        brackets[i] = []\n","\n","    def GetBracket(xVal):\n","        return (xVal-minX)//bracketWidth\n","    \n","    for (i, xVal) in enumerate(x):\n","        if math.isnan(xVal): continue\n","        bracket = GetBracket(xVal)\n","        brackets[bracket].append(y[i])\n","\n","    newBrackets = {}\n","    for bracketNumber in brackets:\n","        minRange = minX+bracketNumber*bracketWidth\n","        maxRange = minRange + bracketWidth\n","        bracketRange = F\"{int(minRange)}-{int(maxRange)}\"\n","        newBrackets[bracketRange] = brackets[bracketNumber]\n","\n","\n","    plotBrackets(brackets,title)\n","    \n","\n","def plotBrackets(brackets,title):\n","    newX = []\n","    newY = []\n","    for bracketName in brackets:\n","        newX.append(bracketName)\n","        newY.append(np.mean(brackets[bracketName]))\n","\n","    plt.figure()\n","    plt.bar(newX,newY)\n","    plt.title(title)\n","\n","\n","def barPlotSurvivalByUniques(data,column,title=\"\"):\n","    x = data[column]\n","    y = data[\"Survived\"].astype(int).values\n","    unique = x.unique()\n","    brackets = {}\n","    for u in unique:\n","        brackets[u] = []\n","    \n","    for (i, xVal) in enumerate(x):\n","        brackets[xVal].append(y[i])\n","    \n","    plotBrackets(brackets,title)\n","\n","def getSurvivalRate(data):\n","    y = data[\"Survived\"].astype(int).values\n","    return sum(y)/len(y)\n","    \n","\n","    \n","\n","trainData = pd.read_csv(trainFilePath)\n","\n","barPlotSurvivalByBrackets(trainData,\"Age\",bracketCount=10,title=\"Age survival train\")\n","barPlotSurvivalByBrackets(testData,\"Age\",bracketCount=10,title=\"Age survival test\")\n","\n","barPlotSurvivalByUniques(trainData,\"Sex\",title=\"Sex survival train\")\n","barPlotSurvivalByUniques(trainData,\"Sex\",title=\"Sex survival test\")\n","\n","print(F\"Survival rates: train:{getSurvivalRate(trainData)}   test:{getSurvivalRate(testData)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","testData.to_csv(\"testDataWithPredicitons.csv\",index=False)\n","testData = testData[[\"PassengerId\",\"Survived\"]]\n","testData.to_csv(\"submission.csv\",index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"nbformat":4,"nbformat_minor":4}
